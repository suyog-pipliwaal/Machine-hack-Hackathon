{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2a0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from   sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from   skimage import io, transform\n",
    "import os\n",
    "from   tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3791626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distribution')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Participants_Data_TLDCC/train.csv')\n",
    "# dataset.head(10)\n",
    "print(len(dataset))\n",
    "plt.figure(figsize=(5,5))\n",
    "dataset['Label'].value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9],[\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10\"])\n",
    "plt.ylabel('number of samples')\n",
    "plt.title(\"Class Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a9cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "default_params = {\n",
    "    \"batch_size_train\": 64,\n",
    "    \"batch_size_test\" : 100,\n",
    "    \"random_seed\"     : 48,\n",
    "    \"learning_rate\"   : 0.001,\n",
    "    \"momentum\"        : 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab716517",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.dataset = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        img_name = os.path.join(self.root_dir+self.dataset.iloc[index, 0])\n",
    "        img = io.imread(img_name)\n",
    "        label = self.dataset.iloc[index, 1]\n",
    "#         label = np.array([label])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a334cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.Grayscale(3),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0edc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_dataset = LeafDataset(\"./Participants_Data_TLDCC/train.csv\", \n",
    "                           './Participants_Data_TLDCC/train/',\n",
    "                           transform=transformers)\n",
    "test_data = LeafDataset(\"./Participants_Data_TLDCC/test.csv\", \n",
    "                        './Participants_Data_TLDCC/test/', \n",
    "                        transform=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df159c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset= True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(leaf_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader =    torch.utils.data.DataLoader(leaf_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(leaf_dataset, batch_size=batch_size,sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54f76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_count(dataset):\n",
    "    class_dict = {} \n",
    "    for img, label in dataset:\n",
    "        class_dict[label] = class_dict.get(label, 0) + 1\n",
    "    for label in class_dict.keys(): \n",
    "        print(\"Images belonging to \" + str(label) + \" are: \" + str(class_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac92f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images belonging to 7 are: 1236\n",
      "Images belonging to 4 are: 3719\n",
      "Images belonging to 0 are: 1519\n",
      "Images belonging to 9 are: 1122\n",
      "Images belonging to 5 are: 678\n",
      "Images belonging to 2 are: 1127\n",
      "Images belonging to 1 are: 719\n",
      "Images belonging to 8 are: 989\n",
      "Images belonging to 3 are: 1335\n",
      "Images belonging to 6 are: 268\n"
     ]
    }
   ],
   "source": [
    "get_class_count(leaf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717a4b5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch2/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "x = torch.randn(16, 3, 224, 224)\n",
    "optimizer.zero_grad()\n",
    "out = compiled_model(x)\n",
    "out.sum().backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b774f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
